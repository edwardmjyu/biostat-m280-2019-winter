---
title: "Biostat M280 Homework 1"
author: "Edward Yu <edwardmjyu@gmail.com>"
subtitle: Due Jan 25 @ 11:59PM
output: html_document
---

    ```{r setup, include=FALSE}
    knitr::opts_chunk$set(echo = TRUE)
    ```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1. Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email.

2. Create a **private** repository `biostat-m280-2019-winter` and add `Hua-Zhou` and `juhkim111` as your collaborators with write permission.

3. Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `master` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `master` branch will be your presentation area. Submit your homework files (R markdown file `Rmd`, `html` file converted from R markdown, all code and data sets to reproduce results) in `master` branch.

4. After each homework due date, teaching assistant and instructor will check out your master branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

## Q2. Linux Shell Commands

The `/home/m280data/NYCHVS` folder on teaching server contains a data set from the New York City Housing and Vacancy Survey. See [2019 ASA Data Challenge Expo](https://www1.nyc.gov/site/hpd/about/nychvs-asa-data-challenge-expo.page) for further details.  
    ```{bash eval=FALSE}
    ls -l /home/m280data/NYCHVS
    ```
Please, do **not** put these data files into Git; they are big. Also do **not** copy them into your directory. Just read from the data folder `/home/m280data/NYCHVS` directly. Use Bash commands to answer following questions.

1. Display the first few lines of ` NYCHVS_1991.csv`.

**Solution:** Show the first few lines by using the command `head`. The `-3` is then used to show only the first 3 lines of the `NYCHVS_1991.csv` file:

    ```{bash}
    head -3 /home/m280data/NYCHVS/NYCHVS_1991.csv
    ```
2. Display number of lines in each `csv` file.

**Solution:** For every data file in the directory that is a `.csv` file, a count of lines is performed:
    ```{bash}
    for datafile in /home/m280data/NYCHVS/*.csv
      do
      wc -l $datafile
    done
    ```

3. Display the 3 files that have the least number of lines

**Solution:** Nearly the same method was used as the last question. However, now I piped the resulting output into a numeric sort and then took the head of the first 3 files, which represents the 3 files with the least number of lines. 
    ```{bash}
    for datafile in /home/m280data/NYCHVS/*.csv
      do
      wc -l $datafile 
    done | sort -n | head -3
    ```

4. What's the output of following bash script?

**Solution:** The bash script outputs a list of all files under the `/home/m280data/NYCHVS/` directory.
    ```{bash, eval=FALSE}
    for datafile in /home/m280data/NYCHVS/*.csv
      do
      ls $datafile
    done
    ```

5. What unique values does the second variable `borough` take in `NYCHVS_1991.csv`? Tabulate how many times each value appears.

**Solution:** The `-F` option in the awk command sets the delimiter as a comma whereas its initial value separates fields as whitespace. Since `borough` is the second variable within the csv file, the `print $2` denotes to awk the location of our variable of interest. The `uniq -c` command counts the number of unique values that borough takes. `NR > 2` is used as a condition since we are only interested in the count of borough values 1 through 5 and their respective counts.

    ```{bash}
    awk -F ',' '{if (NR > 2) print $2}' /home/m280data/NYCHVS/NYCHVS_1991.csv | sort | uniq -c 
    ```

## Q3. More fun with shell

1. You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <https://www.gutenberg.org/files/1342/1342.txt> and save to your local folder. 
    ```{bash, eval=FALSE}
    curl https://www.gutenberg.org/files/1342/1342.txt > pride_and_prejudice.txt
    ```
Do **not** put this text file `pride_and_prejudice.txt` in Git. Using a `for` loop, how would you tabulate the number of times each of the four characters is mentioned?

**Solution:** For each character a search and count is performed on the `pride_and_prejudice.txt` text for that exact name. The `echo` function was added to denote the name associated with he number of times the character was mentioned in the book. This solution does not count any instances where the name might be embedded in a larger word or string within the book.
    ```{bash}
    pride_prejudice="pride_and_prejudice.txt"
    for char in Darcy Elizabeth Jane Lydia
      do 
      echo "${char} - `grep -c "${char}" ${pride_prejudice} `"; 
    done 
    ```

2. What's the difference between the following two commands?
    ```{bash}
    echo 'hello, world' > test1.txt
    ```
    and
    ```{bash}
    echo 'hello, world' >> test2.txt
    ```

**Solution:** The first statement directs the printed text of `hello, world` of the `echo` command into a new file called `test1.txt`. The second statement appends the ouput of the `echo` command into the file test2.txt. If the second command is run multiple times, the `test2.txt` file will continue to append and add `hello, world` as many times as the code is run. 

3. Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:
    ```{bash eval=FALSE}
    #!/bin/sh
    # Select lines from the middle of a file.
    # Usage: bash middle.sh filename end_line num_lines
    head -n "$2" "$1" | tail -n "$3"
    ```
Using `chmod` make the file executable by the owner, and run 
    ```{bash eval=FALSE}
    ./middle.sh pride_and_prejudice.txt 20 5
    ```
Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script. Why do we need the first line of the shell script?

**Solution:** `middle.sh` takes in a text file and from the first 20 lines and displays the last 5 lines of the 20 lines. The meaning of `"$1"`, `"$2"`, and `"$3"` indexes the order of arguments required for middle.sh. '"$1"' refers to the file name, '"$2"' is the number of lines head outputs, and '"$3"' is the number of lines `tail` finally displays from the initial `head` block of lines. The first line of the shell script determines which type of shell should run the program. In our case, the shell type is `sh`. 

## Q4. R Batch Run

In class we discussed using R to organize simulation studies. 

1. Expand the [`runSim.R`](http://hua-zhou.github.io/teaching/biostatm280-2019winter/slides/02-linux/runSim.R) script to include arguments `seed` (random seed), `n` (sample size), `dist` (distribution) and `rep` (number of simulation replicates). When `dist="gaussian"`, generate data from standard normal; when `dist="t1"`, generate data from t-distribution with degree of freedom 1 (same as Cauchy distribution); when `dist="t5"`, generate data from t-distribution with degree of freedom 5. Calling `runSim.R` will (1) set random seed according to argument `seed`, (2) generate data according to argument `dist`, (3) compute the primed-indexed average estimator and the classical sample average estimator for each simulation replicate, (4) report the average mean squared error (MSE)
$$
  \frac{\sum_{r=1}^{\text{rep}} (\widehat \mu_r - \mu_{\text{true}})^2}{\text{rep}}
$$
for both methods.

**Solution:** Additional arguments `seed`, `n`, `dist`, and `rep` were added to `runSim.R` script. A few of the less obvious methods will now be explained more in depth. The R chunk below adds the `rep` argument to the script and simultaneously generates data according to the distribution argument passed. The primed-indexed average estimator and classical sample average estimator are also calculated and combined with the generated data and stored in object `A`. 

    ```{r eval=FALSE, warning=FALSE}
    A <- replicate(rep, c(if (dist == "gaussian") {
                            x = rnorm(n)
                        } else if (dist == "t1") {
                            x = rt(n, 1)
                        } else if (dist == "t5") {
                            x = rt(n, 5)
                        }, estMeanPrimes(x), mean(x)))
    ```


Object `B` is now created to store the values of the primed-indexed average estimator and classical sample average estimator to then calculate the MSE for both methods.

    ```{r eval=FALSE, warning=FALSE}
    B <- tail(A,2)
    ```

Lastly, creating the MSE for both methods:

    ```{r eval=FALSE, warning=FALSE}
    sum(B[1,]^2)/rep
    sum(B[2,]^2)/rep
    ```

Here, I run an example output from the `runSim.R` outputting MSEprimeavg and MSEsampavg using the following parameters:
    ```{bash}
    Rscript runSim.R seed=280 n=100 dist=\"gaussian\" rep=50
    ```

2. Modify the [`autoSim.R`](http://hua-zhou.github.io/teaching/biostatm280-2019winter/slides/02-linux/autoSim.R) script to run simulations with combinations of sample sizes `nVals = seq(100, 500, by=100)` and distributions `distTypes = c("gaussian", "t1", "t5")` and write output to appropriately named files. Use `rep = 50`, and `seed = 280`. 

**Solution:** Here is my 'autoSim.R' code:

    ```{r eval=FALSE}
    # autoSim.R

    nVals <- seq(100, 500, by=100)
    for (n in nVals) {
      for (dist in c("gaussian", "t1", "t5")) {
        oFile <- paste("n", n, "dist", dist, ".txt", sep="")
        sysCall <- paste("nohup Rscript runSim.R n=", n, " dist=", 
                         shQuote(shQuote(dist)), " seed=", 280, " rep=", 50, " > ",
                         oFile, sep="")
        system(sysCall)
        print(paste("sysCall=", sysCall, sep=""))
      }
    }
    ```
Arguments `dist`, `seed`, and `rep` were added to the `sysCall` function to call the `runSim.R` with the correct parameters. The usage of `shQuote(shQuote(dist))` is used to double escape the string passed to the `dist` argument in order for R to properly read the value as a string and not as any other type of object.

Now, running the script we create our outputted files containing MSE values for both methods:
  
    ```{bash}
    Rscript autoSim.R
    ```

3. Write an R script to collect simulation results from output files and print average MSEs in a table of format.

**Solution:** Here is my `collection.R` script. Comments are provided in the code below. However, one particular code to mention, the `Sys.glob()` function, was added to enhance the reproducibility of the code. Normally, the file path would include my ID, but if someone else were to run the code, the code would not work because of the file directory structure. With `Sys.glob()` and the `*` added, we avoid this issue of reproducibility.

    ```{r eval=FALSE}
    #initiating variables before for looping over dist then n.
    distVals <- c("gaussian", "t1", "t5")
    nVals <- seq(100, 500, by = 100)
    interim <- c()
    col1 <- c()
    
    #start of for loops
    for (dist in distVals) {
      for (n in nVals) {
        oFile <- Sys.glob(paste("/home/*/biostat-m280-2019-winter/hw1/n", n, "dist",
                       dist, ".txt", sep=""))
        rtable <- read.table(oFile) 
        rtable <- rtable[, 2] #pulling 2nd column since first column is [1]
        interim <- c(interim, rtable)
        col1 <- c(col1, rep(n,2))
        col1 <- head(col1, 10)
      }
    }
    
    Avg <- rep(c('PrimeAvg', 'SampAvg'), 5)
    
    Final_Table <- data.frame(n = col1, Method = Avg, Gaussian = interim[1:10],
                              t5 = interim[21:30], t1 = interim[11:20])
    Final_Table
    ```

Finally, running the code we get the desired table format:

    ```{bash}
    Rscript collection.R
    ```
    

| $n$ | Method   | Gaussian | $t_5$ | $t_1$ |
|-----|----------|-------|-------|----------|
| 100 | PrimeAvg |       |       |          |
| 100 | SampAvg  |       |       |          |
| 200 | PrimeAvg |       |       |          |
| 200 | SampAvg  |       |       |          |
| 300 | PrimeAvg |       |       |          |
| 300 | SampAvg  |       |       |          |
| 400 | PrimeAvg |       |       |          |
| 400 | SampAvg  |       |       |          |
| 500 | PrimeAvg |       |       |          |
| 500 | SampAvg  |       |       |          |




